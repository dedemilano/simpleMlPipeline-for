{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "877f710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHousing Price Prediction - Model Training\\n\\nThis script trains a Linear Regression model on the preprocessed housing dataset \\nto predict sale prices.\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Housing Price Prediction - Model Training\n",
    "\n",
    "This script trains a Linear Regression model on the preprocessed housing dataset \n",
    "to predict sale prices.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25ab875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24eca890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"deep\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c662f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data(data_dir='../processed_data', version=1):\n",
    "    \"\"\"\n",
    "    Load preprocessed training and testing data.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the preprocessed data files\n",
    "        version: Version number of the preprocessed data\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test: Loaded data splits\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to load as CSV first\n",
    "        X_train = pd.read_csv(os.path.join(data_dir, f'X_train_{version}.csv'))\n",
    "        X_test = pd.read_csv(os.path.join(data_dir, f'X_test_{version}.csv'))\n",
    "        y_train = pd.read_csv(os.path.join(data_dir, f'y_train_{version}.csv')).iloc[:, 0]\n",
    "        y_test = pd.read_csv(os.path.join(data_dir, f'y_test_{version}.csv')).iloc[:, 0]\n",
    "    except:\n",
    "        try:\n",
    "            # If CSV fails, try to load as numpy arrays\n",
    "            X_train = np.load(os.path.join(data_dir, f'X_train_{version}.npy'))\n",
    "            X_test = np.load(os.path.join(data_dir, f'X_test_{version}.npy'))\n",
    "            y_train = pd.read_csv(os.path.join(data_dir, f'y_train_{version}.csv')).iloc[:, 0]\n",
    "            y_test = pd.read_csv(os.path.join(data_dir, f'y_test_{version}.csv')).iloc[:, 0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            print(\"Check file paths and formats.\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f906ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "HOUSING PRICE PREDICTION - MODEL TRAINING\n",
      "==================================================\n",
      "\n",
      "1. LOADING PREPROCESSED DATA\n",
      "------------------------------\n",
      "X_train shape: (1168, 24)\n",
      "X_test shape: (292, 24)\n",
      "y_train shape: (1168,)\n",
      "y_test shape: (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"HOUSING PRICE PREDICTION - MODEL TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load data\n",
    "print(\"\\n1. LOADING PREPROCESSED DATA\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data(data_dir='../processed_data', version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "beee23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_features(X_train, y_train, save_plots=False, output_dir='../plots' , version=1):\n",
    "    \"\"\"\n",
    "    Explore preprocessed features and their correlation with the target.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target values\n",
    "        save_plots: Whether to save plots instead of displaying them\n",
    "        output_dir: Directory to save plots (if save_plots is True)\n",
    "    \"\"\"\n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        print(\"X_train is a numpy array, feature names not available.\")\n",
    "        return\n",
    "    \n",
    "    # Display feature names\n",
    "    print(\"Features after preprocessing:\")\n",
    "    print(X_train.columns.tolist())\n",
    "    \n",
    "    # Feature correlation with target\n",
    "    correlation_data = pd.concat([X_train, y_train.reset_index(drop=True)], axis=1)\n",
    "    correlations = correlation_data.corr()['SalePrice'].sort_values(ascending=False)\n",
    "    \n",
    "    # Display correlation with target\n",
    "    print(\"\\nFeature Correlations with SalePrice:\")\n",
    "    print(correlations.drop('SalePrice'))\n",
    "    \n",
    "    # Create output directory if saving plots\n",
    "    if save_plots:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot feature correlations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    correlations.drop('SalePrice').plot(kind='bar')\n",
    "    plt.title('Feature Correlation with Sale Price', fontsize=14)\n",
    "    plt.xlabel('Features', fontsize=12)\n",
    "    plt.ylabel('Correlation Coefficient', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plots:\n",
    "        plt.savefig(os.path.join(output_dir, f'feature_correlations_{version}.png'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8fdabaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. EXPLORING PREPROCESSED FEATURES\n",
      "------------------------------\n",
      "Features after preprocessing:\n",
      "['LotArea', 'GrLivArea', 'OverallQuality', 'OverallCondition', 'TotalBsmtSF', 'GarageCars', 'HouseAge', 'TotalBath', 'HouseStyle_1.5Unf', 'HouseStyle_1Fam', 'HouseStyle_1Story', 'HouseStyle_2.5Fin', 'HouseStyle_2.5Unf', 'HouseStyle_2Story', 'HouseStyle_SFoyer', 'HouseStyle_SLvl', 'GarageType_BuiltIn', 'GarageType_Detchd', 'GarageType_Missing', 'GarageType_Other', 'SaleType_New', 'SaleType_Other', 'SaleType_WD', 'SaleCondition_Other']\n",
      "\n",
      "Feature Correlations with SalePrice:\n",
      "OverallQuality         0.796219\n",
      "TotalBsmtSF            0.645338\n",
      "GarageCars             0.635389\n",
      "TotalBath              0.596834\n",
      "GrLivArea              0.372400\n",
      "SaleType_New           0.354580\n",
      "LotArea                0.277866\n",
      "GarageType_BuiltIn     0.241354\n",
      "HouseStyle_2Story      0.224236\n",
      "SaleCondition_Other    0.160139\n",
      "HouseStyle_2.5Fin      0.055057\n",
      "SaleType_Other        -0.007496\n",
      "HouseStyle_1Fam       -0.007618\n",
      "HouseStyle_SLvl       -0.029229\n",
      "HouseStyle_2.5Unf     -0.037291\n",
      "HouseStyle_1Story     -0.045337\n",
      "GarageType_Other      -0.055227\n",
      "OverallCondition      -0.066520\n",
      "HouseStyle_1.5Unf     -0.093242\n",
      "HouseStyle_SFoyer     -0.098462\n",
      "GarageType_Missing    -0.232787\n",
      "SaleType_WD           -0.256077\n",
      "GarageType_Detchd     -0.366134\n",
      "HouseAge              -0.523823\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Explore features\n",
    "print(\"\\n2. EXPLORING PREPROCESSED FEATURES\")\n",
    "print(\"-\" * 30)\n",
    "explore_features(X_train, y_train, save_plots=True, output_dir='../plots' , version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3baade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(X_train, y_train, save_plots=False, output_dir='../plots' ,version=1):\n",
    "    \"\"\"\n",
    "    Train a linear regression model with cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target values\n",
    "        save_plots: Whether to save plots instead of displaying them\n",
    "        output_dir: Directory to save plots (if save_plots is True)\n",
    "        \n",
    "    Returns:\n",
    "        Trained linear regression model\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    lr_model = LinearRegression()\n",
    "    \n",
    "    # Perform cross-validation to estimate model performance\n",
    "    cv_scores = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-cv_scores)\n",
    "    \n",
    "    # Display cross-validation results\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(f\"RMSE scores: {rmse_scores}\")\n",
    "    print(f\"Mean RMSE: {rmse_scores.mean():.2f}\")\n",
    "    print(f\"Standard deviation: {rmse_scores.std():.2f}\")\n",
    "\n",
    "    # Train the model on the full training set\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Create output directory if saving plots\n",
    "    if save_plots:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Display model coefficients\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        coefficients = pd.DataFrame({'Feature': X_train.columns, 'Coefficient': lr_model.coef_})\n",
    "        coefficients = coefficients.sort_values('Coefficient', ascending=False)\n",
    "        print(\"\\nModel Coefficients:\")\n",
    "        print(coefficients)\n",
    "        \n",
    "        # Plot coefficients\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        coefficients.plot(x='Feature', y='Coefficient', kind='bar')\n",
    "        plt.title('Linear Regression Coefficients', fontsize=14)\n",
    "        plt.xlabel('Features', fontsize=12)\n",
    "        plt.ylabel('Coefficient Value', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_plots:\n",
    "            plt.savefig(os.path.join(output_dir, f'model_coefficients_{version}.png'))\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"\\nModel Coefficients:\")\n",
    "        print(lr_model.coef_)\n",
    "    \n",
    "    return lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8a019d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. TRAINING LINEAR REGRESSION MODEL\n",
      "------------------------------\n",
      "Cross-Validation Results:\n",
      "RMSE scores: [35177.97559271 46053.89106003 40082.8238683  31772.28861744\n",
      " 39786.14646867]\n",
      "Mean RMSE: 38574.63\n",
      "Standard deviation: 4847.49\n",
      "\n",
      "Model Coefficients:\n",
      "                Feature    Coefficient\n",
      "0               LotArea  202820.440741\n",
      "2        OverallQuality  195005.528815\n",
      "4           TotalBsmtSF  170962.792745\n",
      "1             GrLivArea  125615.426160\n",
      "5            GarageCars   88771.631193\n",
      "3      OverallCondition   47555.649615\n",
      "7             TotalBath   39581.129041\n",
      "20         SaleType_New   36313.390805\n",
      "11    HouseStyle_2.5Fin   33410.462011\n",
      "21       SaleType_Other   26355.745968\n",
      "18   GarageType_Missing   26226.403156\n",
      "16   GarageType_BuiltIn   21902.016305\n",
      "22          SaleType_WD   12632.695810\n",
      "13    HouseStyle_2Story    3690.163465\n",
      "19     GarageType_Other   -4211.288146\n",
      "17    GarageType_Detchd   -4914.359538\n",
      "15      HouseStyle_SLvl   -5241.964395\n",
      "23  SaleCondition_Other   -6120.443331\n",
      "14    HouseStyle_SFoyer   -6346.585336\n",
      "10    HouseStyle_1Story   -7390.939481\n",
      "6              HouseAge   -7833.191704\n",
      "9       HouseStyle_1Fam  -15228.545404\n",
      "12    HouseStyle_2.5Unf  -17292.714210\n",
      "8     HouseStyle_1.5Unf  -23014.833412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"\\n3. TRAINING LINEAR REGRESSION MODEL\")\n",
    "print(\"-\" * 30)\n",
    "lr_model = train_linear_regression(X_train, y_train, save_plots=True, output_dir='../plots' ,version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e70c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, save_plots=False, output_dir='../plots' , version=1):\n",
    "    \"\"\"\n",
    "    Evaluate model performance on test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test target values\n",
    "        save_plots: Whether to save plots instead of displaying them\n",
    "        output_dir: Directory to save plots (if save_plots is True)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    # Make predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Display metrics\n",
    "    print(\"Model Performance on Test Set:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Create output directory if saving plots\n",
    "    if save_plots:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Visualize predictions vs actual values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel('Actual Sale Price', fontsize=12)\n",
    "    plt.ylabel('Predicted Sale Price', fontsize=12)\n",
    "    plt.title('Predicted vs Actual Sale Prices', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plots:\n",
    "        plt.savefig(os.path.join(output_dir, f'predicted_vs_actual_{version}.png'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # Plot residuals\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_pred, residuals, alpha=0.6)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Predicted Sale Price', fontsize=12)\n",
    "    plt.ylabel('Residuals', fontsize=12)\n",
    "    plt.title('Residual Plot', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig(os.path.join(output_dir, f'residual_plot_{version}.png'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # Distribution of residuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(residuals, kde=True)\n",
    "    plt.xlabel('Residuals', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.title('Distribution of Residuals', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig(os.path.join(output_dir, f'residual_distribution_{version}.png'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d96d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. EVALUATING MODEL ON TEST SET\n",
      "------------------------------\n",
      "Model Performance on Test Set:\n",
      "Mean Squared Error (MSE): 2178626095.30\n",
      "Root Mean Squared Error (RMSE): 46675.75\n",
      "Mean Absolute Error (MAE): 25431.97\n",
      "R² Score: 0.6505\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(\"\\n4. EVALUATING MODEL ON TEST SET\")\n",
    "print(\"-\" * 30)\n",
    "evaluation_metrics = evaluate_model(lr_model, X_test, y_test, save_plots=True, output_dir='../plots' , version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "58f150af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, X_train, save_plots=False, output_dir='../plots' ,version=1):\n",
    "    \"\"\"\n",
    "    Analyze feature importance based on model coefficients.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_train: Training features\n",
    "        save_plots: Whether to save plots instead of displaying them\n",
    "        output_dir: Directory to save plots (if save_plots is True)\n",
    "    \"\"\"\n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        print(\"X_train is a numpy array, feature importance analysis requires feature names.\")\n",
    "        return\n",
    "    \n",
    "    # Calculate absolute contribution of each feature\n",
    "    importance = np.abs(model.coef_)\n",
    "    \n",
    "    # Normalize to get relative importance\n",
    "    importance = 100.0 * (importance / importance.sum())\n",
    "    \n",
    "    # Create DataFrame for visualization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Display feature importance\n",
    "    print(\"Feature Importance:\")\n",
    "    print(importance_df)\n",
    "    \n",
    "    # Create output directory if saving plots\n",
    "    if save_plots:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.title('Feature Importance (Absolute Coefficient Value)', fontsize=14)\n",
    "    plt.xlabel('Importance (%)', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig(os.path.join(output_dir, f'feature_importance_{version}.png'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f8cfbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. ANALYZING FEATURE IMPORTANCE\n",
      "------------------------------\n",
      "Feature Importance:\n",
      "                Feature  Importance\n",
      "0               LotArea   17.973551\n",
      "2        OverallQuality   17.281009\n",
      "4           TotalBsmtSF   15.150389\n",
      "1             GrLivArea   11.131794\n",
      "5            GarageCars    7.866768\n",
      "3      OverallCondition    4.214289\n",
      "7             TotalBath    3.507602\n",
      "20         SaleType_New    3.218022\n",
      "11    HouseStyle_2.5Fin    2.960770\n",
      "21       SaleType_Other    2.335595\n",
      "18   GarageType_Missing    2.324133\n",
      "8     HouseStyle_1.5Unf    2.039530\n",
      "16   GarageType_BuiltIn    1.940914\n",
      "12    HouseStyle_2.5Unf    1.532447\n",
      "9       HouseStyle_1Fam    1.349524\n",
      "22          SaleType_WD    1.119485\n",
      "6              HouseAge    0.694162\n",
      "10    HouseStyle_1Story    0.654971\n",
      "14    HouseStyle_SFoyer    0.562422\n",
      "23  SaleCondition_Other    0.542382\n",
      "15      HouseStyle_SLvl    0.464533\n",
      "17    GarageType_Detchd    0.435501\n",
      "19     GarageType_Other    0.373196\n",
      "13    HouseStyle_2Story    0.327015\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature importance\n",
    "print(\"\\n5. ANALYZING FEATURE IMPORTANCE\")\n",
    "print(\"-\" * 30)\n",
    "analyze_feature_importance(lr_model, X_train, save_plots=True, output_dir='../plots' ,version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a90e3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, version=1, models_dir='../models'):\n",
    "    \"\"\"\n",
    "    Save the trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Model to save\n",
    "        version: Version number to use in the saved model filename\n",
    "        models_dir: Directory to save the model\n",
    "    \"\"\"\n",
    "    # Create directory for models if it doesn't exist\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(models_dir, f'linear_regression_model_v{version}.pkl')\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6988b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. SAVING MODEL\n",
      "------------------------------\n",
      "Model saved to ../models\\linear_regression_model_v4.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "print(\"\\n6. SAVING MODEL\")\n",
    "print(\"-\" * 30)\n",
    "save_model(lr_model, version=4, models_dir='../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c37bcd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. SUMMARY\n",
      "------------------------------\n",
      "Model training complete with R² score of 0.6505 on test set.\n",
      "The model has been saved and can be used for predictions.\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n7. SUMMARY\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Model training complete with R² score of {evaluation_metrics['r2']:.4f} on test set.\")\n",
    "print(\"The model has been saved and can be used for predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
